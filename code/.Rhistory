dat <- read.csv("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Emma_med_den_pdx_2dx_10_04_2017.csv")
dat <- read.csv("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Medicare_Oct17/Emma_den_med_pdx_10_04_2017.csv")
dat <- read.csv("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Medicare_Oct17/Emma_den_med_pdx_10_04_2017.csv")
dat <- read.csv(file="/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/Emma_med_11_28_2017.csv")
dim(dat)
View(dat)
dat[1,]
names(dat)
class(dat$adate)
class(dat$ddate)
class(dat$Race_gp)
levels(dat$Race_gp)
class(dat$year)
min(dat$year)
max(dat$year)
class(dat$ddate)
sum(dat$ddate=="")
class(prov_num)
class(dat$prov_num)
blah <- as.numeric(dat$prov_num)
min(blah)
max(blah)
blah <- as.numeric(as.character(dat$prov_num))
min(blah)
min(blah[!is.na(blah)])
miax(blah[!is.na(blah)])
max(blah[!is.na(blah)])
class(dat$X_QID_)
min(dat$X_QID_)
max(dat$X_QID_)
levels(dat$Sex_gp)
class(dat$FIPS)
min(dat$FIPS)
min(dat$FIPS[!is.na(dat$FIPS)])
View(dat[,c("DODFLAG","BENE_DOD")])
adate <- Date(dat$adate)
adate <- as.Date(dat$adate)
?as.Date
dat$adate[`]
dat$adate[1]
''
""
'
aq
q
a;slkdjg
}
[]
`
`
`
dat$adate[1]
adate <- as.Date(dat$adate, format="%d%b%Y")
adate[1:10]
cbind(adate[1:10],dat$adate[1:10])
adate[1:10]
dat$adate[1:10]
dat$adate_r <- as.Date(dat$adate, format="%d%b%Y")
dat$ddate_r <- as.Date(dat$ddate, format="%d%b%Y")
dat$BENE_DOD_r <- as.Date(dat$BENE_DOD_r, format="%d%b%Y")
dat$BENE_DOD_r <- as.Date(dat$BENE_DOD, format="%d%b%Y")
dat_diff <- dat$BENE_DOD_r - dat$ddat_r
summary(dat_diff)
class(dat$BENE_DOD_r)
class(dat$ddat_r)
class(dat$ddate_r)
dat_diff <- dat$BENE_DOD_r - dat$ddate_r
summary(dat_diff)
summarize(dat_diff)
class(dat_diff)
summary(as.numeric(dat_diff))
max(dat)diff
max(dat_diff)
max(dat_diff[!is.na(dat_diff)])
min(dat_diff[!is.na(dat_diff)])
dat_diff <- dat_diff[!is.na(dat_diff)]
summary(dat_diff)
max(dat_diff)
min(dat_diff)
sum(dat_diff < 0)
length(dat_diff)
length_stay <- dat$adate_r - dat$ddate_r
max(length_stay)
min(length_stay)
length_stay <- dat$ddate_r - dat$adate_r
summary(length_stay)
max(length_stay)
min(length_stay)
min(dat_diff)
max(dat_diff)
1275/365.25
length(unique(dat$QID))
length(unique(dat$X_QID_))
dim(dat)
nrow(dat)/length(unique(dat$X_QID_))
nrow(dat)/length(unique(dat$QID))
nrow(dat)/length(unique(dat$prov_num))
max(dat$BENE_DOD_r)
max(dat$BENE_DOD_r,na.rm=T)
medi <- dat
rm(dat)
temp <- read.csv(file="/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/data_JAMA_heatwaves_paper/zip files/County_weather_1999_2010_04_06_2014.CSV")
names(temp)
?merge
names(medi)
View(temp)
temp$adate_r <- as.date(temp$link_ID)
?as.date
temp$adate_r <- as.Date(temp$link_ID)
temp$adate_r[1:10]
medi$adate_r[1:10]
min(medi$adate_r)
min(temp$adate_r)
max(medi$adate_r)
max(temp$adate_r)
dat <- merge(medi, temp, by=c("FIPS","adate_r"), all.x=T)
dim(dat)
dim(medi)
save(dat,file="/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/merged.Rdata")
dim(Dat)
dim(dat)
min(temp$adate_r)
max(temp$adate_r)
keep <- dat$adate_r <= Date("2010-12-31") & dat$adate_r >= Date("1999-01-01")
keep <- dat$adate_r <= as.Date("2010-12-31") & dat$adate_r >= as.Date("1999-01-01")
sum(keep)
dim(dat)
sum(keep)/nrow(dat)
dat <- dat[keep,]
View(dat)
save(dat,file="/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/merged.Rdata")
load(file="/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/merged.Rdata")
View(dat)
head(dat)
View(head(dat))
names(dat)
class(dat$FIPS)
CSA.names <- c("Chicago-Naperville, IL-IN-WI", "New York-Newark, NY-NJ-CT-PA",
"Miami-Fort Lauderdale-Port St. Lucie, FL", "Houston-The Woodlands, TX", "Los Angeles-Long Beach, CA")
for(nm in CSA.names){
}
nm <- CSA.names[1]
nm
CSA.fips <- read.csv(file=paste0("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/R_code/MORETreeS/Data/CSAs/",nm,"_FIPS_codes.csv"),header = F)[,1]
CSA.fips
dat_sub <- subset(dat,FIPS %in% CSA.fips & Emer_adm==1,select=c("QID","Race_gp","Sex_gp","Dual","diag1","adate","temperature_daily_county_mean","temperature_daily_county_min","temperature_daily_county_max"))
save(dat_sub,file=paste0("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/merged_",nm,".Rdata"))
CSA.names <- c("Chicago-Naperville, IL-IN-WI", "New York-Newark, NY-NJ-CT-PA",
"Miami-Fort Lauderdale-Port St. Lucie, FL", "Houston-The Woodlands, TX", "Los Angeles-Long Beach, CA")
for(nm in CSA.names){
# Read in list of relevant FIPS codes
CSA.fips <- read.csv(file=paste0("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/R_code/MORETreeS/Data/CSAs/",nm,"_FIPS_codes.csv"),header = F)[,1]
# Extract data for this city, keeping only relevant variables and emergency admissions only
dat_sub <- subset(dat,FIPS %in% CSA.fips & Emer_adm==1,select=c("QID","Race_gp","Sex_gp","Dual","diag1","adate","temperature_daily_county_mean","temperature_daily_county_min","temperature_daily_county_max"))
# Save dataset
save(dat_sub,file=paste0("/nfs/home/E/ethomas/shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/merged_",nm,".Rdata"))
}
dim(dat_sub)
names(dat_sub)
length(unique(dat_sub$QID))
dim(dat)
require(fst)
read_fst(file="./shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/zipcode_er_part14.fst")
?read_fst
read_fst(path="./shared_space/ci3_nsaph/Emma/Data/Case_crossover_data/zipcode_er_part14.fst")
require(NSAPHutils)
devtools::install_github("NSAPH/NSAPHutils")
require(NSAPHutils)
require(fst)
dir <- "shared_space/ci3_health_data/medicare/gen_admission/1999_2016/targeted_conditions/cache_data/admissions_by_year/"
getwd()
print(list.files(dir))
print(fst.metadata(paste0(dir,"admissions_2000.fst")))
View(fst.metadata(paste0(dir,"admissions_2000.fst")))
require(icd)
getwd()
library(NSAPHutils)
set_threads()
# Make sure working directory is set to moretrees2/code
setwd("/nfs/home/E/ethomas/shared_space/ci3_analysis/moretrees2/code/")
library(data.table)
library(fst)
library(icd)
library(stringr)
library(readr)
admissions_path <- "../data/admissions_resp/"
enviro_path <- "../data/enviro/"
merged_path <- "../data/merged_admissions_enviro/"
# function that gets potential control dates for all case dates in a range
get_control_dates <- function(begin, end) {
dates <- seq(begin, end, by = "day")
controls_dt <- data.table(dates = dates, control_days = rep(list(), length(dates)),
key = "dates")
for (i in 1:nrow(controls_dt)) {
date <- controls_dt$dates[i]
start <- make_date(day = 1, month = month(date), year = year(date))
control_days <- seq(start, start + days_in_month(start) - 1, by = "day") # match on month/year
control_days <- control_days[wday(control_days) == wday(date)] # match on day of week
control_days <- control_days[control_days != date] # remove date itself
controls_dt$control_days[[i]] <- control_days
}
return(controls_dt)
}
admissions_all <- NULL
# set seed because we will randomly select control day
set.seed(973486)
for (year_ in 2000:2014) {
# read in admissions
# NOTE: for now I am ignoring the fact that multiple hospitalizations may occur for same individual
admissions <- read_fst(paste0("../data/admissions_resp/admissions_resp_", year_, ".fst"),
as.data.table = T, columns = c("id", "zip", "adate",
"ccs", "ccs_added_zeros", "ssa_state_cd",
"race_gp", "sex_gp", "age_gp", "dual"))
# select control days (stratified on year, month, day of week)
# get list of potential controls
potential_controls <- get_control_dates(begin = make_date(day = 1, month = 1, year = year_),
end = make_date(day = 31, month = 12, year = year_))
admissions <- merge(admissions, potential_controls, by.x = "adate", by.y = "dates",
all.x = T, all.y = F)
# randomly select one control per case
admissions[ , cdate := lapply(control_days, sample, size = 1)]
admissions[ , cdate := do.call("c", cdate)]
admissions[ , control_days := NULL]
# read in PM2.5 data
pm25 <- read_fst(paste0("../data/enviro/pm_", year_, ".fst"),
as.data.table = T, columns = c("ZIP", "date", "pm25", "pm25_lag1"))
# compute lag01 PM2.5
pm25[ , pm25_lag01_case := (pm25 + pm25_lag1) / 2]
pm25[ , c("pm25","pm25_lag1") := NULL]
# merge lag01 PM2.5 for case and control days
admissions <- merge(admissions, pm25, by.x = c("zip", "adate"), by.y = c("ZIP", "date"),
all.x = T, all.y = F)
setnames(pm25, "pm25_lag01_case", "pm25_lag01_control")
admissions <- merge(admissions, pm25, by.x = c("zip", "cdate"), by.y = c("ZIP", "date"),
all.x = T, all.y = F)
# Remove PM2.5 data
rm(pm25)
# read in temperature & humidity data
temp <- read_fst(paste0("../data/enviro/temp_", year_, ".fst"), as.data.table = T,
columns = c("ZIP", "date", "tmmx", "tmmx_lag1", "rmax", "rmax_lag1"))
# compute lag01 temperature & humidity
temp[ , tmmx_lag01_case := (tmmx + tmmx_lag1) / 2]
temp[ , rmax_lag01_case := (rmax + rmax_lag1) / 2]
temp[ , c("tmmx", "tmmx_lag1", "rmax", "rmax_lag1") := NULL]
# merge temp & humidity data for case and control days
admissions <- merge(admissions, temp, by.x = c("zip", "adate"), by.y = c("ZIP", "date"),
all.x = T, all.y = F)
setnames(temp, c("tmmx_lag01_case", "rmax_lag01_case"),
c("tmmx_lag01_control", "rmax_lag01_control"))
admissions <- merge(admissions, temp, by.x = c("zip", "cdate"), by.y = c("ZIP", "date"),
all.x = T, all.y = F)
# remove temp data
rm(temp)
# read in ozone data
ozone <- read_fst(paste0("../data/enviro/ozone_", year_, ".fst"), as.data.table = T,
columns = c("ZIP", "date", "ozone", "ozone_lag1"))
# Compute lag01 ozone
ozone[ , ozone_lag01_case := (ozone + ozone_lag1) / 2]
ozone[ , c("ozone", "ozone_lag1") := NULL]
# merge ozone data for case and control days
admissions <- merge(admissions, ozone, by.x = c("zip", "adate"), by.y = c("ZIP", "date"),
all.x = T, all.y = F)
setnames(ozone, "ozone_lag01_case", "ozone_lag01_control")
admissions <- merge(admissions, ozone, by.x = c("zip", "cdate"), by.y = c("ZIP", "date"),
all.x = T, all.y = F)
# Remove ozone data
rm(ozone)
# Drop unnecessary variables
# admissions[ , c("adate", "cdate", "zip") := NULL]
# concatenate with other year's data
admissions_all <- rbind(admissions_all, admissions)
# Remove yearly dataset
rm(admissions)
# Keep track of progress
print(year_)
}
# write to file (all admissions)
write_fst(admissions_all, "../data/merged_admissions_enviro/admissions_enviro_resp.fst")
